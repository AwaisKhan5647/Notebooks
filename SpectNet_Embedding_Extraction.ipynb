{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8036218-2e97-4be0-9c80-c6196f446324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F  \n",
    "import torchvision.models as models  # Import this line to access pre-trained models\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3117f61-fe06-40f4-8f45-f5d9fa110e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files(directory, output_file, prefix=\"train_segment_merged_part_\"):\n",
    "    # Identify files with the specified prefix and .csv extension\n",
    "    csv_files = [os.path.join(directory, f) for f in os.listdir(directory) \n",
    "                 if f.startswith(prefix) and f.endswith('.csv')]\n",
    "    \n",
    "    # Load and concatenate all identified files\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        print(f\"Reading file: {file}\")  # Print the name of each file being read\n",
    "        df_list.append(pd.read_csv(file))\n",
    "    \n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Save the merged dataframe to a single CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c62088ca-e87b-45e4-8407-83d7e364f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Extract features and labels\n",
    "    file_names = df.iloc[:, 0]  # File names (not used for training)\n",
    "    labels = df.iloc[:, -1].values  # Labels (1=real, 0=fake)\n",
    "    features = df.iloc[:, 1:-1].values  # Features (1x1084)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    features_normalized = scaler.fit_transform(features)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features_normalized, labels, test_size=0.4, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87620aa7-7a83-4e7b-8913-a8683e112714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68375a83-5e82-4168-9fe7-23fb48c07735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, num_classes):\n",
    "        super(AttentionModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_dim, embedding_dim)\n",
    "        self.attn = torch.nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=2)\n",
    "        self.classifier = torch.nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        attn_output, _ = self.attn(x.unsqueeze(0), x.unsqueeze(0), x.unsqueeze(0))  # Apply attention mechanism\n",
    "        x = attn_output.squeeze(0)\n",
    "        logits = self.classifier(x)\n",
    "        return logits, x  # Return both logits and embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c371a35-fdec-42ac-bf7d-88e506505fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96c534c1-3c3c-444c-8dfd-32bc4279948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrastive_model(model, criterion, optimizer, train_loader, val_loader=None, epochs=50):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    best_auc = 0\n",
    "    best_eer = 1\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            logits, _ = model(x)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = nn.CrossEntropyLoss()(logits, y)  # Using cross-entropy for classification\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        if val_loader:\n",
    "            # Evaluate model on validation set after each epoch\n",
    "            auc_score, cm, eer = test_model(model, val_loader, device)\n",
    "            print(f\"Validation AUC: {auc_score:.4f}, EER: {eer:.4f}\")\n",
    "\n",
    "            # Store the best model\n",
    "            if eer < best_eer or auc_score > best_auc:\n",
    "                best_auc = auc_score\n",
    "                best_eer = eer\n",
    "                best_model = model.state_dict()\n",
    "\n",
    "    # Save the best model\n",
    "    if best_model:\n",
    "        model.load_state_dict(best_model)\n",
    "        print(f\"Best model saved with AUC: {best_auc:.4f}, EER: {best_eer:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37731f0e-527e-49c4-88f3-076974469ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eer(fpr, tpr):\n",
    "    # EER is the point where FPR and (1 - TPR) are closest to each other\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fpr - fnr))  # Find the index where the difference is smallest\n",
    "    eer = fpr[eer_idx]  # The value of FPR at that index is the EER\n",
    "    return eer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2359488-d8cc-4d8d-a765-242e73d75891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, val_loader, device=\"cuda\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for evaluation\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            logits, _ = model(data)\n",
    "            preds = torch.softmax(logits, dim=1)[:, 1]  # Get probabilities for the positive class\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, (all_preds > 0.5).astype(int))\n",
    "\n",
    "    # Compute ROC curve and EER\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_preds)\n",
    "    eer = calculate_eer(fpr, tpr)\n",
    "\n",
    "    return auc_score, cm, eer  # Return all values needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932d3138-c6f6-4008-a8d3-c80a5145659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(features, labels, title, save_path):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_features = tsne.fit_transform(features)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=labels, cmap='viridis', s=10)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd8c52-0483-4f9f-bc82-012372c1703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_path):\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7189ba2e-a4f1-4f5a-be43-c967cb00b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, features):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = model(torch.tensor(features, dtype=torch.float32).cuda())\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "def save_embeddings_to_csv(file_ids, embeddings, labels, output_file):\n",
    "    embeddings_df = pd.DataFrame({\n",
    "        \"file_id\": file_ids,\n",
    "        \"embedding\": [emb.tolist() for emb in embeddings],\n",
    "        \"label\": labels\n",
    "    })\n",
    "    embeddings_df.to_csv(output_file, index=False)\n",
    "    print(f\"Embeddings saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47b0f43d-02da-49d6-ac72-6704c91e78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_local(model_path, weights_path, device=\"cuda\"):\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the full model\n",
    "    loaded_model = torch.load(model_path, map_location=device)\n",
    "    loaded_model.eval()  # Set the model to evaluation mode\n",
    "    print(\"Model and weights successfully loaded from local directory.\")\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6637e9c7-9331-4418-a470-f2963015123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\train_segment_merged_part_1.csv\n",
      "Reading file: C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\train_segment_merged_part_2.csv\n",
      "Reading file: C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\train_segment_merged_part_3.csv\n",
      "Reading file: C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\train_segment_merged_part_4.csv\n",
      "Reading file: C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\train_segment_merged_part_5.csv\n",
      "Reading file: C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\train_segment_merged_part_6.csv\n",
      "Reading file: C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\train_segment_merged_part_7.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Define paths and files\n",
    "csv_dir = r\"C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\\"  # Update with your directory path\n",
    "merged_output_file = \"merged_data.csv\"\n",
    "save_dir = r\"C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\\\\"  # Update with your desired save directory\n",
    "\n",
    "# 2. Merge the CSV files\n",
    "merged_data = merge_csv_files(csv_dir, merged_output_file)\n",
    "\n",
    "# 3. Preprocess data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f6abd6c-526f-49a4-8e77-ea8afe0ea3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create DataLoader\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "val_dataset = AudioDataset(X_val, y_val)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d666136-6e35-41b1-9bf8-78398e749b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.4960\n",
      "Validation AUC: 0.8653, EER: 0.2119\n",
      "Best Model Saved with EER: 0.2119326241134752, AUC: 0.865327665627423\n",
      "Epoch 2/100, Loss: 0.4615\n",
      "Validation AUC: 0.8680, EER: 0.2102\n",
      "Best Model Saved with EER: 0.2102127659574468, AUC: 0.8680128821642937\n",
      "Epoch 3/100, Loss: 0.4539\n",
      "Validation AUC: 0.8791, EER: 0.1983\n",
      "Best Model Saved with EER: 0.19831560283687943, AUC: 0.8790616604350189\n",
      "Epoch 4/100, Loss: 0.4488\n",
      "Validation AUC: 0.8849, EER: 0.1932\n",
      "Best Model Saved with EER: 0.19319148936170213, AUC: 0.8849224967499799\n",
      "Epoch 5/100, Loss: 0.4459\n",
      "Validation AUC: 0.8780, EER: 0.1997\n",
      "Best Model Saved with EER: 0.19319148936170213, AUC: 0.8849224967499799\n",
      "Epoch 6/100, Loss: 0.4433\n",
      "Validation AUC: 0.8707, EER: 0.2049\n",
      "Best Model Saved with EER: 0.19319148936170213, AUC: 0.8849224967499799\n",
      "Epoch 7/100, Loss: 0.4412\n",
      "Validation AUC: 0.8677, EER: 0.2100\n",
      "Best Model Saved with EER: 0.19319148936170213, AUC: 0.8849224967499799\n",
      "Epoch 8/100, Loss: 0.4389\n",
      "Validation AUC: 0.8854, EER: 0.1923\n",
      "Best Model Saved with EER: 0.19234042553191488, AUC: 0.8854199943792982\n",
      "Epoch 9/100, Loss: 0.4380\n",
      "Validation AUC: 0.8874, EER: 0.1900\n",
      "Best Model Saved with EER: 0.19, AUC: 0.8873987999963838\n",
      "Epoch 10/100, Loss: 0.4362\n",
      "Validation AUC: 0.8866, EER: 0.1906\n",
      "Best Model Saved with EER: 0.19, AUC: 0.8873987999963838\n",
      "Epoch 11/100, Loss: 0.4359\n",
      "Validation AUC: 0.8830, EER: 0.1946\n",
      "Best Model Saved with EER: 0.19, AUC: 0.8873987999963838\n",
      "Epoch 12/100, Loss: 0.4347\n",
      "Validation AUC: 0.8878, EER: 0.1897\n",
      "Best Model Saved with EER: 0.1896808510638298, AUC: 0.8878429565782059\n",
      "Epoch 13/100, Loss: 0.4345\n",
      "Validation AUC: 0.8882, EER: 0.1890\n",
      "Best Model Saved with EER: 0.18900709219858156, AUC: 0.8882015505452815\n",
      "Epoch 14/100, Loss: 0.4335\n",
      "Validation AUC: 0.8890, EER: 0.1876\n",
      "Best Model Saved with EER: 0.1876241134751773, AUC: 0.8890351775210912\n",
      "Epoch 15/100, Loss: 0.4325\n",
      "Validation AUC: 0.8874, EER: 0.1884\n",
      "Best Model Saved with EER: 0.1876241134751773, AUC: 0.8890351775210912\n",
      "Epoch 16/100, Loss: 0.4316\n",
      "Validation AUC: 0.8898, EER: 0.1861\n",
      "Best Model Saved with EER: 0.18609929078014184, AUC: 0.889844640352063\n",
      "Epoch 17/100, Loss: 0.4309\n",
      "Validation AUC: 0.8901, EER: 0.1866\n",
      "Best Model Saved with EER: 0.18609929078014184, AUC: 0.889844640352063\n",
      "Epoch 18/100, Loss: 0.4313\n",
      "Validation AUC: 0.8901, EER: 0.1861\n",
      "Best Model Saved with EER: 0.18609929078014184, AUC: 0.889844640352063\n",
      "Epoch 19/100, Loss: 0.4310\n",
      "Validation AUC: 0.8897, EER: 0.1871\n",
      "Best Model Saved with EER: 0.18609929078014184, AUC: 0.889844640352063\n",
      "Epoch 20/100, Loss: 0.4301\n",
      "Validation AUC: 0.8913, EER: 0.1847\n",
      "Best Model Saved with EER: 0.18468085106382978, AUC: 0.8913055441606502\n",
      "Epoch 21/100, Loss: 0.4300\n",
      "Validation AUC: 0.8896, EER: 0.1859\n",
      "Best Model Saved with EER: 0.18468085106382978, AUC: 0.8913055441606502\n",
      "Epoch 22/100, Loss: 0.4297\n",
      "Validation AUC: 0.8907, EER: 0.1859\n",
      "Best Model Saved with EER: 0.18468085106382978, AUC: 0.8913055441606502\n",
      "Epoch 23/100, Loss: 0.4294\n",
      "Validation AUC: 0.8913, EER: 0.1853\n",
      "Best Model Saved with EER: 0.18468085106382978, AUC: 0.8913055441606502\n",
      "Epoch 24/100, Loss: 0.4296\n",
      "Validation AUC: 0.8919, EER: 0.1840\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 25/100, Loss: 0.4282\n",
      "Validation AUC: 0.8862, EER: 0.1896\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 26/100, Loss: 0.4288\n",
      "Validation AUC: 0.8874, EER: 0.1875\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 27/100, Loss: 0.4276\n",
      "Validation AUC: 0.8909, EER: 0.1851\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 28/100, Loss: 0.4270\n",
      "Validation AUC: 0.8902, EER: 0.1846\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 29/100, Loss: 0.4269\n",
      "Validation AUC: 0.8909, EER: 0.1844\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 30/100, Loss: 0.4271\n",
      "Validation AUC: 0.8912, EER: 0.1849\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 31/100, Loss: 0.4272\n",
      "Validation AUC: 0.8925, EER: 0.1842\n",
      "Best Model Saved with EER: 0.18402482269503545, AUC: 0.8918794130244052\n",
      "Epoch 32/100, Loss: 0.4273\n",
      "Validation AUC: 0.8922, EER: 0.1837\n",
      "Best Model Saved with EER: 0.18370567375886523, AUC: 0.8921945030552236\n",
      "Epoch 33/100, Loss: 0.4259\n",
      "Validation AUC: 0.8914, EER: 0.1851\n",
      "Best Model Saved with EER: 0.18370567375886523, AUC: 0.8921945030552236\n",
      "Epoch 34/100, Loss: 0.4254\n",
      "Validation AUC: 0.8888, EER: 0.1865\n",
      "Best Model Saved with EER: 0.18370567375886523, AUC: 0.8921945030552236\n",
      "Epoch 35/100, Loss: 0.4255\n",
      "Validation AUC: 0.8910, EER: 0.1844\n",
      "Best Model Saved with EER: 0.18370567375886523, AUC: 0.8921945030552236\n",
      "Epoch 36/100, Loss: 0.4255\n",
      "Validation AUC: 0.8928, EER: 0.1831\n",
      "Best Model Saved with EER: 0.18312056737588653, AUC: 0.8927502568444654\n",
      "Epoch 37/100, Loss: 0.4253\n",
      "Validation AUC: 0.8885, EER: 0.1879\n",
      "Best Model Saved with EER: 0.18312056737588653, AUC: 0.8927502568444654\n",
      "Epoch 38/100, Loss: 0.4254\n",
      "Validation AUC: 0.8917, EER: 0.1842\n",
      "Best Model Saved with EER: 0.18312056737588653, AUC: 0.8927502568444654\n",
      "Epoch 39/100, Loss: 0.4249\n",
      "Validation AUC: 0.8934, EER: 0.1818\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 40/100, Loss: 0.4245\n",
      "Validation AUC: 0.8890, EER: 0.1863\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 41/100, Loss: 0.4248\n",
      "Validation AUC: 0.8913, EER: 0.1845\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 42/100, Loss: 0.4238\n",
      "Validation AUC: 0.8930, EER: 0.1822\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 43/100, Loss: 0.4247\n",
      "Validation AUC: 0.8924, EER: 0.1829\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 44/100, Loss: 0.4243\n",
      "Validation AUC: 0.8928, EER: 0.1834\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 45/100, Loss: 0.4234\n",
      "Validation AUC: 0.8919, EER: 0.1834\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 46/100, Loss: 0.4240\n",
      "Validation AUC: 0.8928, EER: 0.1827\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 47/100, Loss: 0.4242\n",
      "Validation AUC: 0.8921, EER: 0.1830\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 48/100, Loss: 0.4233\n",
      "Validation AUC: 0.8924, EER: 0.1824\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 49/100, Loss: 0.4236\n",
      "Validation AUC: 0.8904, EER: 0.1859\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 50/100, Loss: 0.4233\n",
      "Validation AUC: 0.8921, EER: 0.1843\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 51/100, Loss: 0.4238\n",
      "Validation AUC: 0.8928, EER: 0.1823\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 52/100, Loss: 0.4234\n",
      "Validation AUC: 0.8917, EER: 0.1844\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 53/100, Loss: 0.4227\n",
      "Validation AUC: 0.8932, EER: 0.1826\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 54/100, Loss: 0.4234\n",
      "Validation AUC: 0.8924, EER: 0.1838\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 55/100, Loss: 0.4234\n",
      "Validation AUC: 0.8934, EER: 0.1821\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 56/100, Loss: 0.4230\n",
      "Validation AUC: 0.8925, EER: 0.1835\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 57/100, Loss: 0.4226\n",
      "Validation AUC: 0.8919, EER: 0.1845\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 58/100, Loss: 0.4233\n",
      "Validation AUC: 0.8921, EER: 0.1834\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 59/100, Loss: 0.4226\n",
      "Validation AUC: 0.8925, EER: 0.1825\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 60/100, Loss: 0.4224\n",
      "Validation AUC: 0.8929, EER: 0.1828\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 61/100, Loss: 0.4224\n",
      "Validation AUC: 0.8935, EER: 0.1818\n",
      "Best Model Saved with EER: 0.18175531914893617, AUC: 0.8933618586781222\n",
      "Epoch 62/100, Loss: 0.4222\n",
      "Validation AUC: 0.8941, EER: 0.1814\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 63/100, Loss: 0.4222\n",
      "Validation AUC: 0.8925, EER: 0.1835\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 64/100, Loss: 0.4223\n",
      "Validation AUC: 0.8888, EER: 0.1877\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 65/100, Loss: 0.4220\n",
      "Validation AUC: 0.8932, EER: 0.1822\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 66/100, Loss: 0.4224\n",
      "Validation AUC: 0.8929, EER: 0.1820\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 67/100, Loss: 0.4221\n",
      "Validation AUC: 0.8937, EER: 0.1820\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 68/100, Loss: 0.4219\n",
      "Validation AUC: 0.8912, EER: 0.1845\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 69/100, Loss: 0.4216\n",
      "Validation AUC: 0.8935, EER: 0.1816\n",
      "Best Model Saved with EER: 0.18136524822695035, AUC: 0.8941012325991671\n",
      "Epoch 70/100, Loss: 0.4217\n",
      "Validation AUC: 0.8942, EER: 0.1813\n",
      "Best Model Saved with EER: 0.18125886524822696, AUC: 0.8941801401417988\n",
      "Epoch 71/100, Loss: 0.4217\n",
      "Validation AUC: 0.8933, EER: 0.1821\n",
      "Best Model Saved with EER: 0.18125886524822696, AUC: 0.8941801401417988\n",
      "Epoch 72/100, Loss: 0.4218\n",
      "Validation AUC: 0.8934, EER: 0.1820\n",
      "Best Model Saved with EER: 0.18125886524822696, AUC: 0.8941801401417988\n",
      "Epoch 73/100, Loss: 0.4216\n",
      "Validation AUC: 0.8942, EER: 0.1809\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 74/100, Loss: 0.4210\n",
      "Validation AUC: 0.8920, EER: 0.1837\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 75/100, Loss: 0.4214\n",
      "Validation AUC: 0.8943, EER: 0.1815\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 76/100, Loss: 0.4214\n",
      "Validation AUC: 0.8936, EER: 0.1822\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 77/100, Loss: 0.4207\n",
      "Validation AUC: 0.8928, EER: 0.1832\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 78/100, Loss: 0.4210\n",
      "Validation AUC: 0.8907, EER: 0.1849\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 79/100, Loss: 0.4207\n",
      "Validation AUC: 0.8941, EER: 0.1815\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 80/100, Loss: 0.4207\n",
      "Validation AUC: 0.8927, EER: 0.1834\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 81/100, Loss: 0.4209\n",
      "Validation AUC: 0.8941, EER: 0.1820\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 82/100, Loss: 0.4213\n",
      "Validation AUC: 0.8936, EER: 0.1820\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 83/100, Loss: 0.4211\n",
      "Validation AUC: 0.8941, EER: 0.1814\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 84/100, Loss: 0.4206\n",
      "Validation AUC: 0.8932, EER: 0.1818\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 85/100, Loss: 0.4208\n",
      "Validation AUC: 0.8944, EER: 0.1813\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 86/100, Loss: 0.4212\n",
      "Validation AUC: 0.8896, EER: 0.1854\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 87/100, Loss: 0.4205\n",
      "Validation AUC: 0.8934, EER: 0.1820\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 88/100, Loss: 0.4204\n",
      "Validation AUC: 0.8932, EER: 0.1826\n",
      "Best Model Saved with EER: 0.18092198581560284, AUC: 0.8942318251022328\n",
      "Epoch 89/100, Loss: 0.4207\n",
      "Validation AUC: 0.8946, EER: 0.1807\n",
      "Best Model Saved with EER: 0.18070921985815602, AUC: 0.8946085588641748\n",
      "Epoch 90/100, Loss: 0.4206\n",
      "Validation AUC: 0.8937, EER: 0.1815\n",
      "Best Model Saved with EER: 0.18070921985815602, AUC: 0.8946085588641748\n",
      "Epoch 91/100, Loss: 0.4207\n",
      "Validation AUC: 0.8941, EER: 0.1819\n",
      "Best Model Saved with EER: 0.18070921985815602, AUC: 0.8946085588641748\n",
      "Epoch 92/100, Loss: 0.4205\n",
      "Validation AUC: 0.8938, EER: 0.1825\n",
      "Best Model Saved with EER: 0.18070921985815602, AUC: 0.8946085588641748\n",
      "Epoch 93/100, Loss: 0.4203\n",
      "Validation AUC: 0.8946, EER: 0.1805\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n",
      "Epoch 94/100, Loss: 0.4204\n",
      "Validation AUC: 0.8938, EER: 0.1820\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n",
      "Epoch 95/100, Loss: 0.4203\n",
      "Validation AUC: 0.8935, EER: 0.1818\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n",
      "Epoch 96/100, Loss: 0.4206\n",
      "Validation AUC: 0.8934, EER: 0.1828\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n",
      "Epoch 97/100, Loss: 0.4199\n",
      "Validation AUC: 0.8908, EER: 0.1843\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n",
      "Epoch 98/100, Loss: 0.4202\n",
      "Validation AUC: 0.8942, EER: 0.1809\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n",
      "Epoch 99/100, Loss: 0.4203\n",
      "Validation AUC: 0.8944, EER: 0.1813\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n",
      "Epoch 100/100, Loss: 0.4203\n",
      "Validation AUC: 0.8918, EER: 0.1824\n",
      "Best Model Saved with EER: 0.18053191489361703, AUC: 0.8945591582409109\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize the model\n",
    "input_dim = X_train.shape[1]\n",
    "embedding_dim = 128\n",
    "num_classes = 2\n",
    "model = AttentionModel(input_dim=input_dim, embedding_dim=embedding_dim, num_classes=num_classes).cuda()\n",
    "\n",
    "# 6. Define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 7. Train the model\n",
    "train_contrastive_model(model, criterion, optimizer, train_loader, val_loader, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b1fa8f2-107a-4843-adc7-503611a1e9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Notebooks\\\\rrl_source\\\\Spectnet_model_embedding'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73eb481d-65a7-44a8-b399-83cd6abf5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\trained_model.pth\n",
      "Model weights saved to C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\\model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Define the save directory (absolute path)\n",
    "save_dir = r\"C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\segmented_features\\train\"\n",
    "\n",
    "# 1. Ensure the save directory exists\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 2. Define the path to save the model and weights\n",
    "model_path = os.path.join(save_dir, \"trained_model.pth\")\n",
    "weights_path = os.path.join(save_dir, \"model_weights.pth\")\n",
    "\n",
    "# 3. Save the entire model (architecture + weights)\n",
    "torch.save(model, model_path)  # Saves both the model architecture and weights\n",
    "\n",
    "# 4. Save only the model weights (state_dict)\n",
    "torch.save(model.state_dict(), weights_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Model weights saved to {weights_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bc4d5-e09e-4305-8b12-c37fa58049cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire model (architecture + weights)\n",
    "model = torch.load(model_path)\n",
    "model.eval()  # Set the model to evaluation mode for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7314c-e971-4e06-9312-06b9e3b780c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35fc7d-7fe2-4314-8108-43944c4a5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Test the model\n",
    "test_model(model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362a113-d2f6-45fa-9c77-50150e34d5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
