{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f98570b5-564d-4c38-ba12-a0eb68865f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU Name: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "device_name: NVIDIA GeForce RTX 4090\n",
      "compute_capability: (8, 9)\n",
      "GPU 0 Total memory: 23.99 GB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all physical devices\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Number of GPUs available: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU Name: {gpu}\")\n",
    "        # Get detailed information about the GPU\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        for key, value in details.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No GPU found.\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def get_gpu_memory():\n",
    "    try:\n",
    "        # Run nvidia-smi to get GPU memory info\n",
    "        result = subprocess.check_output(\n",
    "            ['nvidia-smi', '--query-gpu=memory.total', '--format=csv,nounits,noheader'],\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        # Split the result into lines and convert to integer\n",
    "        gpu_memory = result.strip().split('\\n')\n",
    "        gpu_memory = [int(mem) for mem in gpu_memory]\n",
    "        return gpu_memory\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "gpu_memory = get_gpu_memory()\n",
    "if gpu_memory:\n",
    "    for i, mem in enumerate(gpu_memory):\n",
    "        print(f\"GPU {i} Total memory: {mem / 1024:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU found or nvidia-smi not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffe8c23b-eb31-4561-a5ff-c3c905b3d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from spafe.features.mfcc import mfcc\n",
    "from spafe.features.gfcc import gfcc\n",
    "from spafe.features.lfcc import lfcc\n",
    "from spafe.features.lpc import lpc\n",
    "from spafe.features.msrcc import msrcc\n",
    "from spafe.features.ngcc import ngcc\n",
    "from spafe.features.pncc import pncc\n",
    "from spafe.features.psrcc import psrcc\n",
    "from spafe.features.rplp import rplp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3ea5c2-a798-4def-8287-3362763a2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(audio_file, feature_func, feature_name):\n",
    "    # Load audio file\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "\n",
    "    # Extract feature\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Save feature to numpy file\n",
    "    np.save(f\"{os.path.splitext(audio_file)[0]}_{feature_name}.npy\", feature)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = \"'F:\\Awais_data\\Datasets\\Halftruth\\HAD_train\\train\\conbine\\*.wav'\"\n",
    "\n",
    "    # Extract and save each feature\n",
    "    features = {\n",
    "        \"gfcc\": gfcc,\n",
    "        \"lfcc\": lfcc,\n",
    "        \"lpc\": lpc,\n",
    "        \"mfcc\": mfcc,\n",
    "        \"msrcc\": msrcc,\n",
    "        \"ngcc\": ngcc,\n",
    "        \"pncc\": pncc,\n",
    "        \"psrcc\": psrcc,\n",
    "        \"rplp\": rplp,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d44b0-f213-4072-8f34-792d22f7c056",
   "metadata": {},
   "source": [
    "HalfTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233ebcaf-5625-478f-9614-0d2135af5d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|███████████████████████████████████████████████████████| 53093/53093 [13:01<00:00, 67.94it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_feature(audio_file, feature_func, max_frames):\n",
    "    # Load audio file to get sample rate\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "\n",
    "    # Load audio file up to 4 seconds\n",
    "    signal = signal[:int(4 * sample_rate)]\n",
    "\n",
    "    # Extract feature\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Pad or truncate feature to fixed length\n",
    "    if feature.shape[0] < max_frames:\n",
    "        feature = np.pad(feature, ((0, max_frames - feature.shape[0]), (0, 0)), mode='constant')\n",
    "    elif feature.shape[0] > max_frames:\n",
    "        feature = feature[:max_frames, :]\n",
    "\n",
    "    return feature\n",
    "\n",
    "def read_labels(labels_file):\n",
    "    labels_dict = {}\n",
    "    with open(labels_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            audio_name = parts[0]\n",
    "            label = int(parts[-1])  # Assuming the label is at the last index\n",
    "            labels_dict[audio_name] = label\n",
    "    return labels_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_path = \"F:\\\\Awais_data\\\\Datasets\\\\Halftruth\\\\HAD_train\\\\train\\\\conbine\"\n",
    "    labels_file = \"F:\\Awais_data\\Datasets\\Halftruth\\HAD_train\\HAD_train_label.txt\"\n",
    "    output_feature_file = \"F:\\Awais_data\\Datasets\\Halftruth\\Features\\Training\\HalfTruth_train_mfcc_features.npy\"\n",
    "    output_labels_file = \"F:\\Awais_data\\Datasets\\Halftruth\\Features\\Training\\HalfTruth_train_mfcc_labels.npy\"\n",
    "    max_frames = 40  # Maximum number of frames to consider\n",
    "\n",
    "    # Read labels\n",
    "    labels_dict = read_labels(labels_file)\n",
    "\n",
    "    # Extract features and store labels\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate over the labeled audio files\n",
    "    for audio_name, label in tqdm(labels_dict.items(), desc=\"Extracting features\"):\n",
    "        audio_file = os.path.join(audio_path, audio_name + \".wav\")\n",
    "        # Extract feature\n",
    "        feature = extract_feature(audio_file, mfcc, max_frames)\n",
    "        # Store feature and label\n",
    "        features_list.append(feature)\n",
    "        labels_list.append(label)\n",
    "        # Print label\n",
    "        # print(f\"File: {audio_name}, Label: {'spoof' if label == 0 else 'bonafide'}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    # Save features and labels to numpy files\n",
    "    np.save(output_feature_file, features_array)\n",
    "    np.save(output_labels_file, labels_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a823283-ef63-4630-b2b8-092145a4f48a",
   "metadata": {},
   "source": [
    "ASVspoof2019-LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "462a9b58-788d-472b-aed8-ad964237a2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████████████████████████████████████| 25380/25380 [03:51<00:00, 109.85it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_feature(audio_file, feature_func, max_frames):\n",
    "    # Load audio file to get sample rate\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "\n",
    "    # Load audio file up to 4 seconds\n",
    "    signal = signal[:int(4 * sample_rate)]\n",
    "\n",
    "    # Extract feature\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Pad or truncate feature to fixed length\n",
    "    if feature.shape[0] < max_frames:\n",
    "        feature = np.pad(feature, ((0, max_frames - feature.shape[0]), (0, 0)), mode='constant')\n",
    "    elif feature.shape[0] > max_frames:\n",
    "        feature = feature[:max_frames, :]\n",
    "\n",
    "    return feature\n",
    "\n",
    "def read_labels(labels_file):\n",
    "    labels_dict = {}\n",
    "    with open(labels_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            audio_name = parts[1]\n",
    "            label = parts[4]  # Assuming the label is at the 5th index\n",
    "            # print(label)\n",
    "            label = 1 if label == 'spoof' else 0\n",
    "            labels_dict[audio_name] = label\n",
    "    return labels_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_path = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\ASVspoof2019_LA_train\\\\flac\"\n",
    "    labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\ASVspoof2019_LA_cm_protocols\\\\ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "    output_feature_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\Features\\\\Training\\\\LA_train_lfcc_features.npy\"\n",
    "    output_labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\Features\\\\Training\\\\LA_train_lfcc_labels.npy\"\n",
    "    max_frames = 40  # Maximum number of frames to consider\n",
    "\n",
    "    # Read labels\n",
    "    labels_dict = read_labels(labels_file)\n",
    "\n",
    "    # Extract features and store labels\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate over the labeled audio files\n",
    "    for audio_name, label in tqdm(labels_dict.items(), desc=\"Extracting features\"):\n",
    "        audio_file = os.path.join(audio_path, audio_name + \".flac\")\n",
    "        # Extract feature\n",
    "        feature = extract_feature(audio_file, lfcc, max_frames)\n",
    "        # Store feature and label\n",
    "        features_list.append(feature)\n",
    "        labels_list.append(label)\n",
    "        # Print label\n",
    "        # print(f\"File: {audio_name}, Label: {'spoof' if label == 0 else 'bonafide'}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    # Save features and labels to numpy files\n",
    "    np.save(output_feature_file, features_array)\n",
    "    np.save(output_labels_file, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc837270-6068-428c-a020-acacc485950c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████████████████████████████████████| 24844/24844 [03:38<00:00, 113.95it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_feature(audio_file, feature_func, max_frames):\n",
    "    # Load audio file to get sample rate\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "\n",
    "    # Load audio file up to 4 seconds\n",
    "    signal = signal[:int(4 * sample_rate)]\n",
    "\n",
    "    # Extract feature\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Pad or truncate feature to fixed length\n",
    "    if feature.shape[0] < max_frames:\n",
    "        feature = np.pad(feature, ((0, max_frames - feature.shape[0]), (0, 0)), mode='constant')\n",
    "    elif feature.shape[0] > max_frames:\n",
    "        feature = feature[:max_frames, :]\n",
    "\n",
    "    return feature\n",
    "\n",
    "def read_labels(labels_file):\n",
    "    labels_dict = {}\n",
    "    with open(labels_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            audio_name = parts[1]\n",
    "            label = parts[4]  # Assuming the label is at the 5th index\n",
    "            # print(label)\n",
    "            label = 1 if label == 'spoof' else 0\n",
    "            labels_dict[audio_name] = label\n",
    "    return labels_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_path = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\ASVspoof2019_LA_dev\\\\flac\"\n",
    "    labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\ASVspoof2019_LA_cm_protocols\\\\ASVspoof2019.LA.cm.dev.trl.txt\"\n",
    "    output_feature_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\Features\\\\Development\\\\LA_dev_lfcc_features.npy\"\n",
    "    output_labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\Features\\\\Development\\\\LA_dev_lfcc_labels.npy\"\n",
    "    max_frames = 40  # Maximum number of frames to consider\n",
    "\n",
    "    # Read labels\n",
    "    labels_dict = read_labels(labels_file)\n",
    "\n",
    "    # Extract features and store labels\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate over the labeled audio files\n",
    "    for audio_name, label in tqdm(labels_dict.items(), desc=\"Extracting features\"):\n",
    "        audio_file = os.path.join(audio_path, audio_name + \".flac\")\n",
    "        # Extract feature\n",
    "        feature = extract_feature(audio_file, lfcc, max_frames)\n",
    "        # Store feature and label\n",
    "        features_list.append(feature)\n",
    "        labels_list.append(label)\n",
    "        # Print label\n",
    "        # print(f\"File: {audio_name}, Label: {'spoof' if label == 0 else 'bonafide'}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    # Save features and labels to numpy files\n",
    "    np.save(output_feature_file, features_array)\n",
    "    np.save(output_labels_file, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7991f3d-5f27-4d40-95ca-c49acaa593da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|                                                         | 61/71237 [00:00<09:59, 118.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'F:\\Awais_data\\Datasets\\asvspoof2019\\LA\\ASVspoof2019_LA_eval\\flac\\LA_E_2634822.flac' not found. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|                                                         | 87/71237 [00:00<09:42, 122.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'F:\\Awais_data\\Datasets\\asvspoof2019\\LA\\ASVspoof2019_LA_eval\\flac\\LA_E_5118048.flac' not found. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|                                                        | 116/71237 [00:00<09:03, 130.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'F:\\Awais_data\\Datasets\\asvspoof2019\\LA\\ASVspoof2019_LA_eval\\flac\\LA_E_2161075.flac' not found. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|▏                                                       | 201/71237 [00:01<08:51, 133.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'F:\\Awais_data\\Datasets\\asvspoof2019\\LA\\ASVspoof2019_LA_eval\\flac\\LA_E_7205247.flac' not found. Skipping...\n",
      "File 'F:\\Awais_data\\Datasets\\asvspoof2019\\LA\\ASVspoof2019_LA_eval\\flac\\LA_E_1911910.flac' not found. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|███████████████████████████████████████████████████████| 71237/71237 [12:03<00:00, 98.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf  # Assuming you've imported soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract features\n",
    "def extract_feature(audio_file, feature_func, max_frames):\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"File '{audio_file}' not found. Skipping...\")\n",
    "        return None\n",
    "    \n",
    "    # Load audio file to get sample rate\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "\n",
    "    # Load audio file up to 4 seconds\n",
    "    signal = signal[:int(4 * sample_rate)]\n",
    "\n",
    "    # Extract feature\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Pad or truncate feature to fixed length\n",
    "    if feature.shape[0] < max_frames:\n",
    "        feature = np.pad(feature, ((0, max_frames - feature.shape[0]), (0, 0)), mode='constant')\n",
    "    elif feature.shape[0] > max_frames:\n",
    "        feature = feature[:max_frames, :]\n",
    "\n",
    "    return feature\n",
    "\n",
    "# Function to read labels\n",
    "def read_labels(labels_file):\n",
    "    labels_dict = {}\n",
    "    with open(labels_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            audio_name = parts[1]\n",
    "            label = parts[4]  # Assuming the label is at the 5th index\n",
    "            label = 1 if label == 'spoof' else 0\n",
    "            labels_dict[audio_name] = label\n",
    "    return labels_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_path = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\ASVspoof2019_LA_eval\\\\flac\"\n",
    "    labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\ASVspoof2019_LA_cm_protocols\\\\ASVspoof2019.LA.cm.eval.trl.txt\"\n",
    "    output_feature_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\Features\\\\Evaluation\\\\LA_eval_lfcc_features.npy\"\n",
    "    output_labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\Features\\\\Evaluation\\\\LA_eval_lfcc_labels.npy\"\n",
    "    max_frames = 40  # Maximum number of frames to consider\n",
    "\n",
    "    # Read labels\n",
    "    labels_dict = read_labels(labels_file)\n",
    "\n",
    "    # Extract features and store labels\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate over the labeled audio files\n",
    "    for audio_name, label in tqdm(labels_dict.items(), desc=\"Extracting features\"):\n",
    "        audio_file = os.path.join(audio_path, audio_name + \".flac\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(audio_file):\n",
    "            print(f\"File '{audio_file}' not found. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Extract feature\n",
    "        feature = extract_feature(audio_file, lfcc, max_frames)\n",
    "        \n",
    "        # Store feature and label if feature extraction was successful\n",
    "        if feature is not None:\n",
    "            features_list.append(feature)\n",
    "            labels_list.append(label)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    # Save features and labels to numpy files\n",
    "    np.save(output_feature_file, features_array)\n",
    "    np.save(output_labels_file, labels_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb1511-85d5-4941-b209-7ef7473fd910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e940521b-a8e7-47b4-8aa5-681c2478019b",
   "metadata": {},
   "source": [
    "ASVspoof21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "686d2817-2a00-495d-a3a8-41090f864c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████████████████████████████████| 611829/611829 [22:40:14<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf  # Assuming you've imported soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract features\n",
    "def extract_feature(audio_file, feature_func, max_frames):\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"File '{audio_file}' not found. Skipping...\")\n",
    "        return None\n",
    "    \n",
    "    # Load audio file to get sample rate\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "\n",
    "    # Load audio file up to 4 seconds\n",
    "    signal = signal[:int(4 * sample_rate)]\n",
    "\n",
    "    # Extract feature\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Pad or truncate feature to fixed length\n",
    "    if feature.shape[0] < max_frames:\n",
    "        feature = np.pad(feature, ((0, max_frames - feature.shape[0]), (0, 0)), mode='constant')\n",
    "    elif feature.shape[0] > max_frames:\n",
    "        feature = feature[:max_frames, :]\n",
    "\n",
    "    return feature\n",
    "\n",
    "# Function to read labels\n",
    "def read_labels(labels_file):\n",
    "    labels_dict = {}\n",
    "    with open(labels_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            audio_name = parts[1]\n",
    "            label = parts[5]  # Assuming the label is at the 5th index\n",
    "            label = 1 if label == 'spoof' else 0\n",
    "            labels_dict[audio_name] = label\n",
    "    return labels_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_path = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\ASVspoof2021_DF_eval\\\\flac\"\n",
    "    labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\ASVspoof2021_DF_eval\\\\ASVspoof2021.DF.cm.eval.trl.txt.txt\"\n",
    "    output_feature_file = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\Features\\\\DF\\\\DF_eval_lfcc_features.npy\"\n",
    "    output_labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\Features\\\\DF\\\\DF_eval_lfcc_labels.npy\"\n",
    "    max_frames = 40  # Maximum number of frames to consider\n",
    "\n",
    "    # Read labels\n",
    "    labels_dict = read_labels(labels_file)\n",
    "\n",
    "    # Extract features and store labels\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate over the labeled audio files\n",
    "    for audio_name, label in tqdm(labels_dict.items(), desc=\"Extracting features\"):\n",
    "        audio_file = os.path.join(audio_path, audio_name + \".flac\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(audio_file):\n",
    "            print(f\"File '{audio_file}' not found. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Extract feature\n",
    "        feature = extract_feature(audio_file, lfcc, max_frames)\n",
    "        \n",
    "        # Store feature and label if feature extraction was successful\n",
    "        if feature is not None:\n",
    "            features_list.append(feature)\n",
    "            labels_list.append(label)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    # Save features and labels to numpy files\n",
    "    np.save(output_feature_file, features_array)\n",
    "    np.save(output_labels_file, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16ecde45-ea8c-4338-9e1c-f159aa2a7c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|████████████████████████████████████████████████████| 181566/181566 [25:32<00:00, 118.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf  # Assuming you've imported soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract features\n",
    "def extract_feature(audio_file, feature_func, max_frames):\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"File '{audio_file}' not found. Skipping...\")\n",
    "        return None\n",
    "    \n",
    "    # Load audio file to get sample rate\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "\n",
    "    # Load audio file up to 4 seconds\n",
    "    signal = signal[:int(4 * sample_rate)]\n",
    "\n",
    "    # Extract feature\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Pad or truncate feature to fixed length\n",
    "    if feature.shape[0] < max_frames:\n",
    "        feature = np.pad(feature, ((0, max_frames - feature.shape[0]), (0, 0)), mode='constant')\n",
    "    elif feature.shape[0] > max_frames:\n",
    "        feature = feature[:max_frames, :]\n",
    "\n",
    "    return feature\n",
    "\n",
    "# Function to read labels\n",
    "def read_labels(labels_file):\n",
    "    labels_dict = {}\n",
    "    with open(labels_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            audio_name = parts[1]\n",
    "            label = parts[5]  # Assuming the label is at the 5th index\n",
    "            label = 1 if label == 'spoof' else 0\n",
    "            labels_dict[audio_name] = label\n",
    "    return labels_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_path = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\ASVspoof2021_LA_eval\\\\flac\"\n",
    "    labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\ASVspoof2021_LA_eval\\\\ASVspoof2021.LA.cm.eval.trl.txt.txt\"\n",
    "    output_feature_file = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\Features\\\\LA\\\\LA_eval_mfcc_features.npy\"\n",
    "    output_labels_file = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\Features\\\\LA\\\\LA_eval_mfcc_labels.npy\"\n",
    "    max_frames = 40  # Maximum number of frames to consider\n",
    "\n",
    "    # Read labels\n",
    "    labels_dict = read_labels(labels_file)\n",
    "\n",
    "    # Extract features and store labels\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate over the labeled audio files\n",
    "    for audio_name, label in tqdm(labels_dict.items(), desc=\"Extracting features\"):\n",
    "        audio_file = os.path.join(audio_path, audio_name + \".flac\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(audio_file):\n",
    "            print(f\"File '{audio_file}' not found. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Extract feature\n",
    "        feature = extract_feature(audio_file, mfcc, max_frames)\n",
    "        \n",
    "        # Store feature and label if feature extraction was successful\n",
    "        if feature is not None:\n",
    "            features_list.append(feature)\n",
    "            labels_list.append(label)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(features_list)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    # Save features and labels to numpy files\n",
    "    np.save(output_feature_file, features_array)\n",
    "    np.save(output_labels_file, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781ff20-f24e-444c-827d-f35b4f763205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e18920c9-d6f7-44ef-b6e6-bb1872b82008",
   "metadata": {},
   "source": [
    "WaveFake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f8163ec-13ca-414f-a4cf-3652549e0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_common_voices_prompts_from_conformer_fastsp\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_full_band_melgan: 100%|█| 13100/13100 [02:0\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_hifiGAN: 100%|█| 13100/13100 [02:12<00:00, \n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_melgan: 100%|█| 13100/13100 [02:09<00:00, 1\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_melgan_large: 100%|█| 13100/13100 [02:11<00\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_multi_band_melgan: 100%|█| 13100/13100 [02:\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_parallel_wavegan: 100%|█| 13099/13099 [02:0\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\ljspeech_waveglow: 100%|█| 13100/13100 [02:08<00:00,\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\jsut_multi_band_melgan: 100%|█| 5000/5000 [00:49<00:\n",
      "Processing F:\\Awais_data\\Datasets\\wavefake_dataset\\generated_audio\\jsut_parallel_wavegan: 100%|█| 5000/5000 [00:49<00:0\n"
     ]
    }
   ],
   "source": [
    "# Function to extract features\n",
    "def extract_feature(audio_file, feature_func, max_frames):\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"File '{audio_file}' not found. Skipping...\")\n",
    "        return None\n",
    "    \n",
    "    # Load audio file to get sample rate\n",
    "    signal, sample_rate = sf.read(audio_file)\n",
    "    signal = signal[:int(4 * sample_rate)]\n",
    "    feature = feature_func(signal, fs=sample_rate)\n",
    "\n",
    "    # Pad or truncate feature to fixed length\n",
    "    if feature.shape[0] < max_frames:\n",
    "        feature = np.pad(feature, ((0, max_frames - feature.shape[0]), (0, 0)), mode='constant')\n",
    "    elif feature.shape[0] > max_frames:\n",
    "        feature = feature[:max_frames, :]\n",
    "    return feature\n",
    "\n",
    "# Function to process audio files in directories\n",
    "def process_directory(directory, feature_func, max_frames):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in tqdm(files, desc=f\"Processing {root}\"):\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_file = os.path.join(root, file)\n",
    "                feature = extract_feature(audio_file, feature_func, max_frames)\n",
    "                \n",
    "                if feature is not None:\n",
    "                    features_list.append(feature)\n",
    "                    labels_list.append(1)  # All labels are set to 1 (spoof)\n",
    "    \n",
    "    return np.array(features_list), np.array(labels_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"F:\\\\Awais_data\\\\Datasets\\\\wavefake_dataset\\\\generated_audio\"\n",
    "    ljspeech_dirs = [\n",
    "        \"ljspeech_common_voices_prompts_from_conformer_fastspeech2\",\n",
    "        \"ljspeech_full_band_melgan\",\"ljspeech_hifiGAN\",\"ljspeech_melgan\",\"ljspeech_melgan_large\",\n",
    "        \"ljspeech_multi_band_melgan\",\"ljspeech_parallel_wavegan\",\"ljspeech_waveglow\"\n",
    "    ]\n",
    "    jsut_dirs = [\n",
    "        \"jsut_multi_band_melgan\",\n",
    "        \"jsut_parallel_wavegan\"\n",
    "    ]\n",
    "\n",
    "    output_feature_file_ljspeech = \"F:\\\\Awais_data\\\\Datasets\\\\wavefake_dataset\\\\generated_audio\\\\Features\\\\ljspeech\\\\ljspeech_features.npy\"\n",
    "    output_labels_file_ljspeech = \"F:\\\\Awais_data\\\\Datasets\\\\wavefake_dataset\\\\generated_audio\\\\Features\\\\ljspeech\\\\ljspeech_labels.npy\"\n",
    "    output_feature_file_jsut = \"F:\\\\Awais_data\\\\Datasets\\\\wavefake_dataset\\\\generated_audio\\\\Features\\\\jsut\\\\jsut_mfcc_features.npy\"\n",
    "    output_labels_file_jsut = \"F:\\\\Awais_data\\\\Datasets\\\\wavefake_dataset\\\\generated_audio\\\\Features\\\\jsut\\\\jsut_mfcc_labels.npy\"\n",
    "    max_frames = 40  # Maximum number of frames to consider\n",
    "\n",
    "    \n",
    "    # Process ljspeech directories\n",
    "    ljspeech_features_list = []\n",
    "    ljspeech_labels_list = []\n",
    "    for ljspeech_dir in ljspeech_dirs:\n",
    "        dir_path = os.path.join(base_dir, ljspeech_dir)\n",
    "        features, labels = process_directory(dir_path, lfcc, max_frames)\n",
    "        ljspeech_features_list.append(features)\n",
    "        ljspeech_labels_list.append(labels)\n",
    "    \n",
    "    ljspeech_features = np.vstack(ljspeech_features_list)\n",
    "    ljspeech_labels = np.hstack(ljspeech_labels_list)\n",
    "\n",
    "    # Save ljspeech features and labels\n",
    "    np.save(output_feature_file_ljspeech, ljspeech_features)\n",
    "    np.save(output_labels_file_ljspeech, ljspeech_labels)\n",
    "\n",
    "    # Process jsut directories\n",
    "    jsut_features_list = []\n",
    "    jsut_labels_list = []\n",
    "    for jsut_dir in jsut_dirs:\n",
    "        dir_path = os.path.join(base_dir, jsut_dir)\n",
    "        features, labels = process_directory(dir_path, mfcc, max_frames)\n",
    "        jsut_features_list.append(features)\n",
    "        jsut_labels_list.append(labels)\n",
    "    \n",
    "    jsut_features = np.vstack(jsut_features_list)\n",
    "    jsut_labels = np.hstack(jsut_labels_list)\n",
    "\n",
    "    # Save jsut features and labels\n",
    "    np.save(output_feature_file_jsut, jsut_features)\n",
    "    np.save(output_labels_file_jsut, jsut_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a6877-b91f-4724-96f5-e3889665a83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec72bb-111c-4e18-889a-417d86ee0c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23bc91-7236-4539-9a52-d4e353768d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb44cf5-c0b2-4d1f-8d8d-7f97714446dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e33dd1-2dc7-48d7-8579-b62efd35b38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dafa41-7d2d-4906-aebb-1c29f968ceef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (test_gpu)",
   "language": "python",
   "name": "test_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
