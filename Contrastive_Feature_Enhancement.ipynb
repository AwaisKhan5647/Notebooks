{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "376ab3a5-d6dd-4470-8af2-e63ca2556e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F  \n",
    "import torchvision.models as models  # Import this line to access pre-trained models\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728fc6f2-16c5-44f5-b26d-3293fa2831f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data shape: (533035, 1086)\n"
     ]
    }
   ],
   "source": [
    "# --------- 1. Merge CSV Files ---------\n",
    "def merge_csv_files(directory, output_file, prefix=\"train_segment_merged_part_\"):\n",
    "    # Identify files with the specified prefix and .csv extension\n",
    "    csv_files = [os.path.join(directory, f) for f in os.listdir(directory) \n",
    "                 if f.startswith(prefix) and f.endswith('.csv')]\n",
    "    \n",
    "    # Load and concatenate all identified files\n",
    "    df_list = [pd.read_csv(file) for file in csv_files]\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Save the merged dataframe to a single CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    return merged_df\n",
    "\n",
    "# Merge the files\n",
    "csv_dir = r\"C:\\Notebooks\\rrl_source\\dataset_raw\\merge\\new2\"\n",
    "output_file = \"merged_features.csv\"\n",
    "merged_data = merge_csv_files(csv_dir, output_file)\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Merged data shape: {merged_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bccb1094-326b-4a9a-883c-ff5850ff575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 2. Preprocess Data ---------\n",
    "def preprocess_data(df):\n",
    "    # Extract features and labels\n",
    "    file_names = df.iloc[:, 0]  # File names (not used for training)\n",
    "    labels = df.iloc[:, -1].values  # Labels (1=real, 0=fake)\n",
    "    features = df.iloc[:, 1:-1].values  # Features (1x1084)\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    features_normalized = scaler.fit_transform(features)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(features_normalized, labels, test_size=0.4, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, features_normalized, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46fc148c-27d0-434d-8153-0109f4ef7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.features[idx]  # The anchor sample\n",
    "        \n",
    "        # Create a positive pair\n",
    "        pos_idx = idx\n",
    "        while pos_idx == idx:  # Ensure different sample for positive pair\n",
    "            pos_idx = random.choice(range(len(self.labels)))\n",
    "        positive = self.features[pos_idx]\n",
    "        \n",
    "        # Create a negative pair\n",
    "        neg_idx = random.choice(range(len(self.labels)))  # Randomly choose a negative sample\n",
    "        while self.labels[neg_idx] == self.labels[idx]:  # Ensure different class for negative pair\n",
    "            neg_idx = random.choice(range(len(self.labels)))\n",
    "        negative = self.features[neg_idx]\n",
    "        \n",
    "        return anchor, positive, negative\n",
    "\n",
    "# Assuming the `merged_data` is a pandas DataFrame you passed to preprocess_data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, features, labels = preprocess_data(merged_data)\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "val_dataset = AudioDataset(X_val, y_val)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e82e8d26-3b7c-42cb-9edf-3ead19bfe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, num_classes=2, num_heads=8):\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "        # Embedding layer to transform input features into the desired embedding dimension\n",
    "        self.embedding = nn.Linear(input_dim, embedding_dim)\n",
    "\n",
    "        # Positional Encoding (for attention layers)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, embedding_dim))\n",
    "\n",
    "        # Multi-Head Self Attention Layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        # Deeper Feed Forward Network after Attention\n",
    "        self.fc1 = nn.Linear(embedding_dim, embedding_dim * 2)\n",
    "        self.fc2 = nn.Linear(embedding_dim * 2, embedding_dim * 4)\n",
    "        self.fc3 = nn.Linear(embedding_dim * 4, num_classes)\n",
    "\n",
    "        # Layer Normalization for stability\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding input to match the attention input size\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # Add Positional Encoding\n",
    "        x = x + self.positional_encoding\n",
    "\n",
    "        # Attention Layer (self-attention)\n",
    "        attn_output, attn_weights = self.attention(x, x, x)  # (batch_size, seq_len, embedding_dim), (batch_size, seq_len, seq_len)\n",
    "\n",
    "        # Layer normalization after attention\n",
    "        x = self.layer_norm(attn_output + x)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x.squeeze(1), attn_weights  # Squeeze to get batch_size, num_classes output\n",
    "input_dim = 1084\n",
    "embedding_dim = 128\n",
    "num_classes = 2\n",
    "# Instantiate the model\n",
    "model = AttentionModel(input_dim=input_dim, embedding_dim=embedding_dim, num_classes=num_classes).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99d645c0-37d6-4e4c-b597-99825fb3247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self, anchor_emb, positive_emb, negative_emb):\n",
    "        # Normalize the embeddings to unit length (cosine similarity)\n",
    "        anchor_emb = nn.functional.normalize(anchor_emb, dim=1)\n",
    "        positive_emb = nn.functional.normalize(positive_emb, dim=1)\n",
    "        negative_emb = nn.functional.normalize(negative_emb, dim=1)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        pos_sim = torch.sum(anchor_emb * positive_emb, dim=1)\n",
    "        neg_sim = torch.sum(anchor_emb * negative_emb, dim=1)\n",
    "\n",
    "        # Compute the contrastive loss\n",
    "        loss_pos = -torch.log(torch.exp(pos_sim / self.temperature) / (torch.exp(pos_sim / self.temperature) + torch.exp(neg_sim / self.temperature)))\n",
    "        loss = loss_pos.mean()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "criterion = NTXentLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf12471d-2d54-4918-a1f1-c8e377d82b23",
   "metadata": {},
   "outputs": [],
   "source": [
    " #--------- 6. Optimizer ---------\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23b60146-705a-40db-81e5-eb4ec9d724e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6844\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6085, EER: 0.5783\n",
      "Confusion Matrix (Validation):\n",
      "[[23168 83439]\n",
      " [13555 93052]]\n",
      "Epoch 2/100, Loss: 0.6471\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6214, EER: 0.5941\n",
      "Confusion Matrix (Validation):\n",
      "[[31352 75255]\n",
      " [17331 89276]]\n",
      "Epoch 3/100, Loss: 0.6399\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6467, EER: 0.6131\n",
      "Confusion Matrix (Validation):\n",
      "[[39500 67107]\n",
      " [20522 86085]]\n",
      "Epoch 4/100, Loss: 0.6316\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6406, EER: 0.6105\n",
      "Confusion Matrix (Validation):\n",
      "[[46712 59895]\n",
      " [25832 80775]]\n",
      "Epoch 5/100, Loss: 0.6301\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6459, EER: 0.6114\n",
      "Confusion Matrix (Validation):\n",
      "[[37716 68891]\n",
      " [19811 86796]]\n",
      "Epoch 6/100, Loss: 0.6285\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6530, EER: 0.6166\n",
      "Confusion Matrix (Validation):\n",
      "[[48873 57734]\n",
      " [26754 79853]]\n",
      "Epoch 7/100, Loss: 0.6267\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6501, EER: 0.6110\n",
      "Confusion Matrix (Validation):\n",
      "[[53783 52824]\n",
      " [31189 75418]]\n",
      "Epoch 8/100, Loss: 0.6223\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6185, EER: 0.5945\n",
      "Confusion Matrix (Validation):\n",
      "[[42431 64176]\n",
      " [25794 80813]]\n",
      "Epoch 9/100, Loss: 0.6188\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6507, EER: 0.6198\n",
      "Confusion Matrix (Validation):\n",
      "[[57015 49592]\n",
      " [32564 74043]]\n",
      "Epoch 10/100, Loss: 0.6196\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6615, EER: 0.6251\n",
      "Confusion Matrix (Validation):\n",
      "[[51112 55495]\n",
      " [27392 79215]]\n",
      "Epoch 11/100, Loss: 0.6123\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6530, EER: 0.6166\n",
      "Confusion Matrix (Validation):\n",
      "[[57755 48852]\n",
      " [33639 72968]]\n",
      "Epoch 12/100, Loss: 0.6122\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6551, EER: 0.6210\n",
      "Confusion Matrix (Validation):\n",
      "[[33201 73406]\n",
      " [16440 90167]]\n",
      "Epoch 13/100, Loss: 0.6112\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6669, EER: 0.6282\n",
      "Confusion Matrix (Validation):\n",
      "[[52251 54356]\n",
      " [27525 79082]]\n",
      "Epoch 14/100, Loss: 0.6079\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6712, EER: 0.6343\n",
      "Confusion Matrix (Validation):\n",
      "[[54404 52203]\n",
      " [28298 78309]]\n",
      "Epoch 15/100, Loss: 0.6096\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6595, EER: 0.6287\n",
      "Confusion Matrix (Validation):\n",
      "[[59052 47555]\n",
      " [32786 73821]]\n",
      "Epoch 16/100, Loss: 0.6088\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6647, EER: 0.6300\n",
      "Confusion Matrix (Validation):\n",
      "[[58248 48359]\n",
      " [31611 74996]]\n",
      "Epoch 17/100, Loss: 0.6088\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6307, EER: 0.6013\n",
      "Confusion Matrix (Validation):\n",
      "[[19811 86796]\n",
      " [ 9816 96791]]\n",
      "Epoch 18/100, Loss: 0.6045\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6672, EER: 0.6308\n",
      "Confusion Matrix (Validation):\n",
      "[[35075 71532]\n",
      " [16542 90065]]\n",
      "Epoch 19/100, Loss: 0.6012\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6813, EER: 0.6449\n",
      "Confusion Matrix (Validation):\n",
      "[[65619 40988]\n",
      " [35006 71601]]\n",
      "Epoch 20/100, Loss: 0.6044\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6713, EER: 0.6329\n",
      "Confusion Matrix (Validation):\n",
      "[[44224 62383]\n",
      " [21439 85168]]\n",
      "Epoch 21/100, Loss: 0.5981\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6784, EER: 0.6411\n",
      "Confusion Matrix (Validation):\n",
      "[[57642 48965]\n",
      " [29540 77067]]\n",
      "Epoch 22/100, Loss: 0.5941\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6794, EER: 0.6383\n",
      "Confusion Matrix (Validation):\n",
      "[[59844 46763]\n",
      " [31346 75261]]\n",
      "Epoch 23/100, Loss: 0.5942\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6836, EER: 0.6442\n",
      "Confusion Matrix (Validation):\n",
      "[[63028 43579]\n",
      " [32901 73706]]\n",
      "Epoch 24/100, Loss: 0.5958\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6702, EER: 0.6327\n",
      "Confusion Matrix (Validation):\n",
      "[[68234 38373]\n",
      " [39944 66663]]\n",
      "Epoch 25/100, Loss: 0.5939\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6833, EER: 0.6473\n",
      "Confusion Matrix (Validation):\n",
      "[[67409 39198]\n",
      " [36191 70416]]\n",
      "Epoch 26/100, Loss: 0.5905\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6819, EER: 0.6440\n",
      "Confusion Matrix (Validation):\n",
      "[[65235 41372]\n",
      " [34857 71750]]\n",
      "Epoch 27/100, Loss: 0.5916\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6791, EER: 0.6429\n",
      "Confusion Matrix (Validation):\n",
      "[[64979 41628]\n",
      " [35054 71553]]\n",
      "Epoch 28/100, Loss: 0.5912\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6849, EER: 0.6462\n",
      "Confusion Matrix (Validation):\n",
      "[[65668 40939]\n",
      " [34962 71645]]\n",
      "Epoch 29/100, Loss: 0.5930\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6833, EER: 0.6421\n",
      "Confusion Matrix (Validation):\n",
      "[[61216 45391]\n",
      " [31737 74870]]\n",
      "Epoch 30/100, Loss: 0.5898\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6759, EER: 0.6383\n",
      "Confusion Matrix (Validation):\n",
      "[[65839 40768]\n",
      " [36562 70045]]\n",
      "Epoch 31/100, Loss: 0.5856\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6811, EER: 0.6415\n",
      "Confusion Matrix (Validation):\n",
      "[[62690 43917]\n",
      " [33356 73251]]\n",
      "Epoch 32/100, Loss: 0.5854\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6874, EER: 0.6450\n",
      "Confusion Matrix (Validation):\n",
      "[[69125 37482]\n",
      " [38248 68359]]\n",
      "Epoch 33/100, Loss: 0.5820\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6892, EER: 0.6520\n",
      "Confusion Matrix (Validation):\n",
      "[[70699 35908]\n",
      " [38297 68310]]\n",
      "Epoch 34/100, Loss: 0.5857\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6873, EER: 0.6513\n",
      "Confusion Matrix (Validation):\n",
      "[[71861 34746]\n",
      " [39465 67142]]\n",
      "Epoch 35/100, Loss: 0.5862\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6873, EER: 0.6462\n",
      "Confusion Matrix (Validation):\n",
      "[[67968 38639]\n",
      " [36752 69855]]\n",
      "Epoch 36/100, Loss: 0.5845\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6924, EER: 0.6531\n",
      "Confusion Matrix (Validation):\n",
      "[[70745 35862]\n",
      " [37993 68614]]\n",
      "Epoch 37/100, Loss: 0.5841\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6838, EER: 0.6434\n",
      "Confusion Matrix (Validation):\n",
      "[[61454 45153]\n",
      " [31946 74661]]\n",
      "Epoch 38/100, Loss: 0.5867\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6794, EER: 0.6403\n",
      "Confusion Matrix (Validation):\n",
      "[[64468 42139]\n",
      " [34882 71725]]\n",
      "Epoch 39/100, Loss: 0.5816\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6887, EER: 0.6477\n",
      "Confusion Matrix (Validation):\n",
      "[[68746 37861]\n",
      " [37267 69340]]\n",
      "Epoch 40/100, Loss: 0.5847\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6892, EER: 0.6503\n",
      "Confusion Matrix (Validation):\n",
      "[[72534 34073]\n",
      " [40416 66191]]\n",
      "Epoch 41/100, Loss: 0.5783\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6949, EER: 0.6560\n",
      "Confusion Matrix (Validation):\n",
      "[[75418 31189]\n",
      " [42238 64369]]\n",
      "Epoch 42/100, Loss: 0.5779\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6951, EER: 0.6573\n",
      "Confusion Matrix (Validation):\n",
      "[[73230 33377]\n",
      " [39324 67283]]\n",
      "Epoch 43/100, Loss: 0.5758\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6919, EER: 0.6522\n",
      "Confusion Matrix (Validation):\n",
      "[[70451 36156]\n",
      " [37878 68729]]\n",
      "Epoch 44/100, Loss: 0.5778\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6905, EER: 0.6505\n",
      "Confusion Matrix (Validation):\n",
      "[[72997 33610]\n",
      " [40690 65917]]\n",
      "Epoch 45/100, Loss: 0.5767\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6939, EER: 0.6500\n",
      "Confusion Matrix (Validation):\n",
      "[[70092 36515]\n",
      " [38126 68481]]\n",
      "Epoch 46/100, Loss: 0.5759\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6905, EER: 0.6532\n",
      "Confusion Matrix (Validation):\n",
      "[[69071 37536]\n",
      " [36499 70108]]\n",
      "Epoch 47/100, Loss: 0.5747\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6904, EER: 0.6529\n",
      "Confusion Matrix (Validation):\n",
      "[[62649 43958]\n",
      " [31595 75012]]\n",
      "Epoch 48/100, Loss: 0.5775\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6944, EER: 0.6545\n",
      "Confusion Matrix (Validation):\n",
      "[[74075 32532]\n",
      " [40882 65725]]\n",
      "Epoch 49/100, Loss: 0.5738\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6981, EER: 0.6567\n",
      "Confusion Matrix (Validation):\n",
      "[[76230 30377]\n",
      " [42874 63733]]\n",
      "Epoch 50/100, Loss: 0.5730\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6913, EER: 0.6521\n",
      "Confusion Matrix (Validation):\n",
      "[[73792 32815]\n",
      " [41114 65493]]\n",
      "Epoch 51/100, Loss: 0.5724\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6947, EER: 0.6530\n",
      "Confusion Matrix (Validation):\n",
      "[[71187 35420]\n",
      " [38531 68076]]\n",
      "Epoch 52/100, Loss: 0.5666\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6946, EER: 0.6562\n",
      "Confusion Matrix (Validation):\n",
      "[[74171 32436]\n",
      " [40700 65907]]\n",
      "Epoch 53/100, Loss: 0.5700\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6973, EER: 0.6569\n",
      "Confusion Matrix (Validation):\n",
      "[[75465 31142]\n",
      " [41999 64608]]\n",
      "Epoch 54/100, Loss: 0.5685\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6990, EER: 0.6607\n",
      "Confusion Matrix (Validation):\n",
      "[[84508 22099]\n",
      " [50954 55653]]\n",
      "Epoch 55/100, Loss: 0.5685\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6950, EER: 0.6578\n",
      "Confusion Matrix (Validation):\n",
      "[[81758 24849]\n",
      " [48255 58352]]\n",
      "Epoch 56/100, Loss: 0.5678\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6999, EER: 0.6604\n",
      "Confusion Matrix (Validation):\n",
      "[[70475 36132]\n",
      " [36264 70343]]\n",
      "Epoch 57/100, Loss: 0.5692\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6942, EER: 0.6539\n",
      "Confusion Matrix (Validation):\n",
      "[[73194 33413]\n",
      " [40063 66544]]\n",
      "Epoch 58/100, Loss: 0.5735\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6952, EER: 0.6553\n",
      "Confusion Matrix (Validation):\n",
      "[[70135 36472]\n",
      " [37023 69584]]\n",
      "Epoch 59/100, Loss: 0.5704\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6936, EER: 0.6536\n",
      "Confusion Matrix (Validation):\n",
      "[[70267 36340]\n",
      " [37500 69107]]\n",
      "Epoch 60/100, Loss: 0.5689\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6921, EER: 0.6556\n",
      "Confusion Matrix (Validation):\n",
      "[[75478 31129]\n",
      " [42082 64525]]\n",
      "Epoch 61/100, Loss: 0.5623\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6971, EER: 0.6575\n",
      "Confusion Matrix (Validation):\n",
      "[[75839 30768]\n",
      " [42020 64587]]\n",
      "Epoch 62/100, Loss: 0.5625\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6985, EER: 0.6574\n",
      "Confusion Matrix (Validation):\n",
      "[[73790 32817]\n",
      " [40224 66383]]\n",
      "Epoch 63/100, Loss: 0.5638\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7017, EER: 0.6607\n",
      "Confusion Matrix (Validation):\n",
      "[[87326 19281]\n",
      " [54425 52182]]\n",
      "Epoch 64/100, Loss: 0.5694\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7002, EER: 0.6608\n",
      "Confusion Matrix (Validation):\n",
      "[[92000 14607]\n",
      " [60576 46031]]\n",
      "Epoch 65/100, Loss: 0.5641\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7036, EER: 0.6624\n",
      "Confusion Matrix (Validation):\n",
      "[[78261 28346]\n",
      " [43663 62944]]\n",
      "Epoch 66/100, Loss: 0.5628\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7022, EER: 0.6631\n",
      "Confusion Matrix (Validation):\n",
      "[[79558 27049]\n",
      " [44563 62044]]\n",
      "Epoch 67/100, Loss: 0.5639\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6992, EER: 0.6563\n",
      "Confusion Matrix (Validation):\n",
      "[[72840 33767]\n",
      " [39354 67253]]\n",
      "Epoch 68/100, Loss: 0.5636\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6992, EER: 0.6606\n",
      "Confusion Matrix (Validation):\n",
      "[[74634 31973]\n",
      " [40059 66548]]\n",
      "Epoch 69/100, Loss: 0.5614\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7020, EER: 0.6581\n",
      "Confusion Matrix (Validation):\n",
      "[[73525 33082]\n",
      " [39501 67106]]\n",
      "Epoch 70/100, Loss: 0.5634\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.6882, EER: 0.6481\n",
      "Confusion Matrix (Validation):\n",
      "[[69074 37533]\n",
      " [37491 69116]]\n",
      "Epoch 71/100, Loss: 0.5621\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7038, EER: 0.6653\n",
      "Confusion Matrix (Validation):\n",
      "[[81968 24639]\n",
      " [47104 59503]]\n",
      "Epoch 72/100, Loss: 0.5559\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7095, EER: 0.6661\n",
      "Confusion Matrix (Validation):\n",
      "[[93433 13174]\n",
      " [62444 44163]]\n",
      "Epoch 73/100, Loss: 0.5639\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7063, EER: 0.6650\n",
      "Confusion Matrix (Validation):\n",
      "[[87898 18709]\n",
      " [54453 52154]]\n",
      "Epoch 74/100, Loss: 0.5655\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7068, EER: 0.6643\n",
      "Confusion Matrix (Validation):\n",
      "[[89825 16782]\n",
      " [57506 49101]]\n",
      "Epoch 75/100, Loss: 0.5601\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7107, EER: 0.6674\n",
      "Confusion Matrix (Validation):\n",
      "[[93755 12852]\n",
      " [63526 43081]]\n",
      "Epoch 76/100, Loss: 0.5604\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7092, EER: 0.6657\n",
      "Confusion Matrix (Validation):\n",
      "[[90748 15859]\n",
      " [58698 47909]]\n",
      "Epoch 77/100, Loss: 0.5621\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7005, EER: 0.6615\n",
      "Confusion Matrix (Validation):\n",
      "[[80503 26104]\n",
      " [46497 60110]]\n",
      "Epoch 78/100, Loss: 0.5562\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7065, EER: 0.6643\n",
      "Confusion Matrix (Validation):\n",
      "[[89855 16752]\n",
      " [57720 48887]]\n",
      "Epoch 79/100, Loss: 0.5629\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7051, EER: 0.6621\n",
      "Confusion Matrix (Validation):\n",
      "[[90558 16049]\n",
      " [58538 48069]]\n",
      "Epoch 80/100, Loss: 0.5536\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7128, EER: 0.6696\n",
      "Confusion Matrix (Validation):\n",
      "[[93334 13273]\n",
      " [62440 44167]]\n",
      "Epoch 81/100, Loss: 0.5557\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7077, EER: 0.6650\n",
      "Confusion Matrix (Validation):\n",
      "[[91217 15390]\n",
      " [59013 47594]]\n",
      "Epoch 82/100, Loss: 0.5558\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7052, EER: 0.6646\n",
      "Confusion Matrix (Validation):\n",
      "[[89455 17152]\n",
      " [56949 49658]]\n",
      "Epoch 83/100, Loss: 0.5590\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7040, EER: 0.6630\n",
      "Confusion Matrix (Validation):\n",
      "[[89334 17273]\n",
      " [57148 49459]]\n",
      "Epoch 84/100, Loss: 0.5556\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7150, EER: 0.6694\n",
      "Confusion Matrix (Validation):\n",
      "[[93200 13407]\n",
      " [61997 44610]]\n",
      "Epoch 85/100, Loss: 0.5578\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7093, EER: 0.6662\n",
      "Confusion Matrix (Validation):\n",
      "[[91895 14712]\n",
      " [60817 45790]]\n",
      "Epoch 86/100, Loss: 0.5511\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7057, EER: 0.6628\n",
      "Confusion Matrix (Validation):\n",
      "[[91721 14886]\n",
      " [60531 46076]]\n",
      "Epoch 87/100, Loss: 0.5555\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7031, EER: 0.6612\n",
      "Confusion Matrix (Validation):\n",
      "[[85566 21041]\n",
      " [51663 54944]]\n",
      "Epoch 88/100, Loss: 0.5572\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7153, EER: 0.6705\n",
      "Confusion Matrix (Validation):\n",
      "[[91678 14929]\n",
      " [59191 47416]]\n",
      "Epoch 89/100, Loss: 0.5529\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7173, EER: 0.6724\n",
      "Confusion Matrix (Validation):\n",
      "[[93036 13571]\n",
      " [61458 45149]]\n",
      "Epoch 90/100, Loss: 0.5537\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7094, EER: 0.6679\n",
      "Confusion Matrix (Validation):\n",
      "[[91701 14906]\n",
      " [59702 46905]]\n",
      "Epoch 91/100, Loss: 0.5522\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7088, EER: 0.6637\n",
      "Confusion Matrix (Validation):\n",
      "[[92234 14373]\n",
      " [60742 45865]]\n",
      "Epoch 92/100, Loss: 0.5495\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7168, EER: 0.6709\n",
      "Confusion Matrix (Validation):\n",
      "[[92775 13832]\n",
      " [61169 45438]]\n",
      "Epoch 93/100, Loss: 0.5501\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7033, EER: 0.6627\n",
      "Confusion Matrix (Validation):\n",
      "[[87228 19379]\n",
      " [54024 52583]]\n",
      "Epoch 94/100, Loss: 0.5488\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7124, EER: 0.6702\n",
      "Confusion Matrix (Validation):\n",
      "[[92748 13859]\n",
      " [61599 45008]]\n",
      "Epoch 95/100, Loss: 0.5522\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7114, EER: 0.6672\n",
      "Confusion Matrix (Validation):\n",
      "[[89879 16728]\n",
      " [57092 49515]]\n",
      "Epoch 96/100, Loss: 0.5513\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7064, EER: 0.6647\n",
      "Confusion Matrix (Validation):\n",
      "[[87559 19048]\n",
      " [54025 52582]]\n",
      "Epoch 97/100, Loss: 0.5503\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7144, EER: 0.6688\n",
      "Confusion Matrix (Validation):\n",
      "[[93692 12915]\n",
      " [62706 43901]]\n",
      "Epoch 98/100, Loss: 0.5508\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7140, EER: 0.6686\n",
      "Confusion Matrix (Validation):\n",
      "[[92407 14200]\n",
      " [60911 45696]]\n",
      "Epoch 99/100, Loss: 0.5509\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7135, EER: 0.6693\n",
      "Confusion Matrix (Validation):\n",
      "[[94011 12596]\n",
      " [63188 43419]]\n",
      "Epoch 100/100, Loss: 0.5508\n",
      "Evaluating on Validation Set...\n",
      "Validation AUC: 0.7129, EER: 0.6689\n",
      "Confusion Matrix (Validation):\n",
      "[[91235 15372]\n",
      " [58865 47742]]\n",
      "Evaluating on Test Set after Training...\n",
      "Test AUC: 0.7174, EER: 0.6727\n",
      "Confusion Matrix (Test):\n",
      "[[91600 15007]\n",
      " [58645 47962]]\n"
     ]
    }
   ],
   "source": [
    "def train_contrastive_model(model, criterion, optimizer, train_loader, val_loader, test_loader, epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for anchor, positive, negative in train_loader:  # Fetch pairs\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get embeddings for anchor, positive, and negative pairs\n",
    "            anchor_emb, _ = model(anchor)  \n",
    "            positive_emb, _ = model(positive)  \n",
    "            negative_emb, _ = model(negative)  \n",
    "\n",
    "            # Contrastive loss (NT-Xent Loss)\n",
    "            loss = criterion(anchor_emb, positive_emb, negative_emb)  # Pass all three embeddings at once\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Evaluate on validation set only during training\n",
    "        print(\"Evaluating on Validation Set...\")\n",
    "        val_auc, val_confusion, val_eer = evaluate_model(model, val_loader, device)\n",
    "        print(f\"Validation AUC: {val_auc:.4f}, EER: {val_eer:.4f}\")\n",
    "        print(f\"Confusion Matrix (Validation):\\n{val_confusion}\")\n",
    "\n",
    "    # After training is complete, evaluate on the test set\n",
    "    print(\"Evaluating on Test Set after Training...\")\n",
    "    test_auc, test_confusion, test_eer = evaluate_model(model, test_loader, device)\n",
    "    print(f\"Test AUC: {test_auc:.4f}, EER: {test_eer:.4f}\")\n",
    "    print(f\"Confusion Matrix (Test):\\n{test_confusion}\")\n",
    "\n",
    "# Now you can call the train_contrastive_model function with all three loaders\n",
    "train_contrastive_model(model, criterion, optimizer, train_loader, val_loader, test_loader, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68567ff1-9330-4867-9111-5e57c6accd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 8. t-SNE Visualization ---------\n",
    "def plot_tsne(features, labels, title, save_path):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_features = tsne.fit_transform(features)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=labels, cmap='viridis', s=10)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "# t-SNE before training\n",
    "plot_tsne(features[:1000], labels[:1000], \"t-SNE Before Training\", \"tsne_before.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "436e0883-7407-4bac-a4e5-006ad75078f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionModel(\n",
       "  (embedding): Linear(in_features=1084, out_features=128, bias=True)\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-SNE after training\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf739105-1dc2-414f-bd65-69e1d4c9f1d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use torch.float32 dtype for input\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 3\u001b[0m     final_embeddings, _ \u001b[38;5;241m=\u001b[39m model(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Get only the embeddings (ignore attention_weights)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     final_embeddings \u001b[38;5;241m=\u001b[39m final_embeddings\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Convert embeddings to CPU for visualization\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plot_tsne(final_embeddings, labels[:\u001b[38;5;241m10000\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-SNE After Training\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtsne_after.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Use torch.float32 dtype for input\n",
    "with torch.no_grad():\n",
    "    final_embeddings, _ = model(torch.tensor(features[:10000], dtype=torch.float32).cuda())  # Get only the embeddings (ignore attention_weights)\n",
    "    final_embeddings = final_embeddings.cpu().numpy()  # Convert embeddings to CPU for visualization\n",
    "\n",
    "plot_tsne(final_embeddings, labels[:10000], \"t-SNE After Training\", \"tsne_after.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54fb17-2574-49e2-a7bc-5cfc863a67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ce09e-a891-49ff-8819-e915df99e90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16c106-a561-4457-890e-29df7ddfa67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
