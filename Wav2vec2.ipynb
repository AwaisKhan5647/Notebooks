{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de904e2-6fcc-49ee-bbfb-fcc18392a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0\n",
      "CUDA available: True\n",
      "GPU device name: NVIDIA GeForce RTX 4090\n",
      "Number of available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if PyTorch is installed properly\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "# Check if CUDA (GPU support) is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "if cuda_available:\n",
    "    # Check the GPU device name\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(\"GPU device name:\", gpu_name)\n",
    "    # Check the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Number of available GPUs:\", num_gpus)\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58519b84-30b5-47c2-ad9f-a2f6a5df5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, roc_curve, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac306379-f1bb-43b5-80c9-8e0a105811f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6df27e8-a0d7-44c3-bd1e-9d522b485df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Wav2Vec2 model and feature extractor\n",
    "# model_name = \"facebook/wav2vec2-large-960h\"\n",
    "# feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "# model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "# min_duration = 0.6  # Minimum duration for padding/truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b956d29e-ba56-4216-98cc-d9b807509656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to the GPU\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d3460-8666-47f3-8ce6-979afa26abdc",
   "metadata": {},
   "source": [
    "Reading Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14875b00-1f88-4984-977e-8ac3bb7bd91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W2V\n",
    "# XLSR\n",
    "# Set paths to feature files\n",
    "data_dir = \"F:\\\\Awais_data\\\\Datasets\\\\asvspoof2019\\\\LA\\\\Features\\\\SSL\"\n",
    "data_dir1 = \"F:\\\\Awais_data\\\\Datasets\\\\ASV21\\\\Features\\\\SSL\\\\W2V\\\\LA\\\\\"\n",
    "\n",
    "X_train_hidden_file = os.path.join(data_dir, \"W2V_Train_hidden_states_features.npy\")\n",
    "X_val_hidden_file = os.path.join(data_dir, \"W2V_dev_hidden_states_features.npy\")\n",
    "# X_test_hidden_file = os.path.join(data_dir, \"W2V_eval_hidden_states_features.npy\")\n",
    "X_test_hidden_file = os.path.join(data_dir1, \"W2V_LA_hidden_states_features01.npy\")\n",
    "\n",
    "# X_train_cnn_file = os.path.join(data_dir, \"XLSR_Train_features_last_cnn_layer.npy\")\n",
    "# X_val_cnn_file = os.path.join(data_dir, \"XLSR_dev_features_last_cnn_layer.npy\")\n",
    "# X_test_cnn_file = os.path.join(data_dir, \"XLSR_eval_features_last_cnn_layer.npy\")\n",
    "y_train_file = os.path.join(data_dir, \"W2V_Train_labels.npy\")\n",
    "y_val_file = os.path.join(data_dir, \"W2V_dev_labels.npy\")\n",
    "y_test_file = os.path.join(data_dir1, \"W2V_LA_labels01.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4af8d17a-8fbc-474e-a886-ad57ae5051de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features and labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6/6 [10:27<00:00, 104.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load features and labels\n",
    "def load_features(file_path):\n",
    "    return np.load(file_path)\n",
    "\n",
    "# Load features and labels with progress bar\n",
    "print(\"Loading features and labels...\")\n",
    "with tqdm(total=6) as pbar:\n",
    "    X_train_hidden = torch.tensor(load_features(X_train_hidden_file), device=device, dtype=torch.float32)\n",
    "    pbar.update(1)\n",
    "    X_val_hidden = torch.tensor(load_features(X_val_hidden_file), device=device, dtype=torch.float32)\n",
    "    pbar.update(1)\n",
    "    X_test_hidden = torch.tensor(load_features(X_test_hidden_file), device=device, dtype=torch.float32)\n",
    "    pbar.update(1)\n",
    "    # X_train_cnn = torch.tensor(load_features(X_train_cnn_file), device=device, dtype=torch.float32)\n",
    "    # pbar.update(1)\n",
    "    # X_val_cnn = torch.tensor(load_features(X_val_cnn_file), device=device, dtype=torch.float32)\n",
    "    # pbar.update(1)\n",
    "    # X_test_cnn = torch.tensor(load_features(X_test_cnn_file), device=device, dtype=torch.float32)\n",
    "    # pbar.update(1)\n",
    "    y_train = torch.tensor(load_features(y_train_file), device=device, dtype=torch.float32)\n",
    "    pbar.update(1)\n",
    "    y_val = torch.tensor(load_features(y_val_file), device=device, dtype=torch.float32)\n",
    "    pbar.update(1)\n",
    "    y_test = torch.tensor(load_features(y_test_file), device=device, dtype=torch.float32)\n",
    "    pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7c94da-d37a-4eed-a743-7e3152c21b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hidden Features Shape: torch.Size([25380, 50176])\n",
      "Validation Hidden Features Shape: torch.Size([24844, 50176])\n",
      "Test Hidden Features Shape: torch.Size([40000, 203776])\n",
      "Training Labels Shape: torch.Size([25380])\n",
      "Validation Labels Shape: torch.Size([24844])\n",
      "Test Labels Shape: torch.Size([40000])\n"
     ]
    }
   ],
   "source": [
    "# Print shapes and sizes\n",
    "print(\"Training Hidden Features Shape:\", X_train_hidden.shape)\n",
    "print(\"Validation Hidden Features Shape:\", X_val_hidden.shape)\n",
    "print(\"Test Hidden Features Shape:\", X_test_hidden.shape)\n",
    "# print(\"Training CNN Features Shape:\", X_train_cnn.shape)\n",
    "# print(\"Validation CNN Features Shape:\", X_val_cnn.shape)\n",
    "# print(\"Test CNN Features Shape:\", X_test_cnn.shape)\n",
    "print(\"Training Labels Shape:\", y_train.shape)\n",
    "print(\"Validation Labels Shape:\", y_val.shape)\n",
    "print(\"Test Labels Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72159029-db5d-4f3a-b133-7fe90b937f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 239.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reshape features with progress bar\n",
    "print(\"Reshaping features...\")\n",
    "with tqdm(total=3) as pbar:\n",
    "    X_train_hidden = X_train_hidden.view(X_train_hidden.shape[0], -1)\n",
    "    pbar.update(1)\n",
    "    X_val_hidden = X_val_hidden.view(X_val_hidden.shape[0], -1)\n",
    "    pbar.update(1)\n",
    "    X_test_hidden = X_test_hidden.view(X_test_hidden.shape[0], -1)\n",
    "    pbar.update(1)\n",
    "    # X_train_cnn = X_train_cnn.view(X_train_cnn.shape[0], -1)\n",
    "    # pbar.update(1)\n",
    "    # X_val_cnn = X_val_cnn.view(X_val_cnn.shape[0], -1)\n",
    "    # pbar.update(1)\n",
    "    # X_test_cnn = X_test_cnn.view(X_test_cnn.shape[0], -1)\n",
    "    # pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e3cded-9b65-46a2-83fa-94aba0085bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train_hidden\n",
    "X_val = X_val_hidden\n",
    "X_test = X_test_hidden\n",
    "\n",
    "# X_train = X_train_cnn\n",
    "# X_val = X_val_cnn\n",
    "# X_test = X_test_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "431c72c3-7d2e-43b5-a004-4536a3405bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization\n",
      "tensor([-0.1370, -0.0350, -0.0693,  ..., -1.1063,  0.6121,  0.1675],\n",
      "       device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor([ 0.2082,  0.2715, -0.0374,  ..., -0.2409,  0.2648,  0.1941],\n",
      "       device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor([-0.7414,  0.2916,  0.1293,  ..., -0.7211,  0.9813,  0.2331],\n",
      "       device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "Shapes\n",
      "torch.Size([25380, 50176])\n",
      "torch.Size([25380])\n",
      "torch.Size([24844, 50176])\n",
      "torch.Size([24844])\n",
      "torch.Size([40000, 203776])\n",
      "torch.Size([40000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization\")\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_val[0])\n",
    "print(y_val[0])\n",
    "print(X_test[0])\n",
    "print(y_test[0])\n",
    "print(\"Shapes\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8f503c-4afa-41b3-ba0a-e40d89501b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing features...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 30.37 GiB. GPU 0 has a total capacity of 23.99 GiB of which 0 bytes is free. Of the allocated memory 49.14 GiB is allocated by PyTorch, and 21.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m X_train \u001b[38;5;241m=\u001b[39m batch_standardize(X_train, batch_size)\n\u001b[0;32m     28\u001b[0m X_val \u001b[38;5;241m=\u001b[39m batch_standardize(X_val, batch_size)\n\u001b[1;32m---> 29\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_standardize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m, in \u001b[0;36mbatch_standardize\u001b[1;34m(X, batch_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m std \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Standardize in batches\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m standardized \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[0;32m     20\u001b[0m     batch \u001b[38;5;241m=\u001b[39m X[i\u001b[38;5;241m*\u001b[39mbatch_size:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size]\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 30.37 GiB. GPU 0 has a total capacity of 23.99 GiB of which 0 bytes is free. Of the allocated memory 49.14 GiB is allocated by PyTorch, and 21.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Function to standardize in batches\n",
    "def batch_standardize(X, batch_size):\n",
    "    num_features = X.size(1)\n",
    "    mean = torch.zeros(num_features, device=device)\n",
    "    std = torch.zeros(num_features, device=device)\n",
    "    \n",
    "    # Compute mean and std in batches\n",
    "    num_batches = (X.size(0) + batch_size - 1) // batch_size\n",
    "    for i in range(num_batches):\n",
    "        batch = X[i*batch_size:(i+1)*batch_size]\n",
    "        mean += batch.mean(dim=0)\n",
    "        std += batch.std(dim=0)\n",
    "    \n",
    "    mean /= num_batches\n",
    "    std /= num_batches\n",
    "    \n",
    "    # Standardize in batches\n",
    "    standardized = torch.empty_like(X)\n",
    "    for i in range(num_batches):\n",
    "        batch = X[i*batch_size:(i+1)*batch_size]\n",
    "        standardized[i*batch_size:(i+1)*batch_size] = (batch - mean) / std\n",
    "    \n",
    "    return standardized\n",
    "\n",
    "print(\"Standardizing features...\")\n",
    "batch_size = 500  # Adjust batch size based on available memory\n",
    "X_train = batch_standardize(X_train, batch_size)\n",
    "X_val = batch_standardize(X_val, batch_size)\n",
    "X_test = batch_standardize(X_test, batch_size)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01149044-7de6-41bc-b872-d434256fcc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After normalization\")\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_val[0])\n",
    "print(y_val[0])\n",
    "print(X_test[0])\n",
    "print(y_test[0])\n",
    "print(\"Shapes\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ddb224-5200-40e7-99a3-112195c853b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the visualize_features function\n",
    "# def visualize_features(X, y, title):\n",
    "#     X_embedded = TSNE(n_components=2).fit_transform(X.cpu())\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y.cpu(), cmap='viridis', alpha=0.5)\n",
    "#     plt.colorbar(scatter)\n",
    "#     plt.title(title)\n",
    "#     plt.show()\n",
    "\n",
    "# # Define the function to visualize positive and negative classes separately\n",
    "# def visualize_class(X, y, class_label, title):\n",
    "#     X_class = X[y == class_label]\n",
    "#     X_embedded = TSNE(n_components=2).fit_transform(X_class.cpu())\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c='green' if class_label == 1 else 'red', alpha=0.5)\n",
    "#     plt.title(title)\n",
    "#     plt.show()\n",
    "\n",
    "# # Load your data as PyTorch tensors\n",
    "# # For example, assuming the data is already loaded into variables X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# # Visualize training set\n",
    "# # visualize_features(X_train, y_train, \"Training Set\")\n",
    "\n",
    "# # Visualize validation set\n",
    "# # visualize_features(X_val, y_val, \"Validation Set\")\n",
    "\n",
    "# # Visualize test set\n",
    "# # visualize_features(X_test, y_test, \"Test Set\")\n",
    "\n",
    "# # Visualize combined data\n",
    "# # X_combined = torch.cat([X_train, X_val, X_test], dim=0)\n",
    "# # y_combined = torch.cat([y_train, y_val, y_test], dim=0)\n",
    "# # visualize_features(X_combined, y_combined, \"Combined Training, Validation and Testing Set\")\n",
    "\n",
    "# # Visualize positive and negative classes separately for each set\n",
    "\n",
    "# # Training Set\n",
    "# visualize_class(X_train, y_train, 1, \"Training Set - Positive Class\")\n",
    "# visualize_class(X_train, y_train, 0, \"Training Set - Negative Class\")\n",
    "\n",
    "# # Validation Set\n",
    "# visualize_class(X_val, y_val, 1, \"Validation Set - Positive Class\")\n",
    "# visualize_class(X_val, y_val, 0, \"Validation Set - Negative Class\")\n",
    "\n",
    "# # Test Set\n",
    "# visualize_class(X_test, y_test, 1, \"Test Set - Positive Class\")\n",
    "# visualize_class(X_test, y_test, 0, \"Test Set - Negative Class\")\n",
    "\n",
    "# # Combined Set\n",
    "# # visualize_class(X_combined, y_combined, 1, \"Combined Set - Positive Class\")\n",
    "# visualize_class(X_combined, y_combined, 0, \"Combined Set - Negative Class\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8efa3-c516-4144-964f-400fb4bd25af",
   "metadata": {},
   "source": [
    "MLP Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c3206-4369-4547-a00f-640df9902c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad654e-c20b-4750-9e07-126f55e757f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model\n",
    "# Define the MLP model\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af0866-a15f-4832-8cd0-83ff219391ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters as a configuration dictionary\n",
    "config = {\n",
    "    'hidden_dim': 1024,\n",
    "    'output_dim': 1,  # Assuming binary classification\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.0001,\n",
    "    'model_save_path': 'W2V_best_mlp_model_asv21_hid01'  # Base path for saving the model\n",
    "}\n",
    "# Automatically determine input_dim from training data\n",
    "input_dim = X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d6608-06cb-4924-aaaf-f8924c5d7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets and dataloaders\n",
    "def create_dataloader(X, y, batch_size):\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "train_val_loader = create_dataloader(torch.cat((X_train, X_val)), torch.cat((y_train, y_val)), config['batch_size'])\n",
    "test_loader = create_dataloader(X_test, y_test, config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2174f47-1056-4c70-92f1-617e8a49fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = MLPClassifier(input_dim, config['hidden_dim'], config['output_dim']).cuda()\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c61eca-6022-42b9-a1fe-9d205e60c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "summary(model, (input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a2eeb-6f39-4cbf-8077-40644eb2645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        X_batch, y_batch = X_batch.cuda(), y_batch.float().cuda()  # Ensure target is float for BCEWithLogitsLoss\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(tqdm(dataloader, desc=\"Evaluation\", leave=False)):\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.float().cuda()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            all_outputs.extend(torch.sigmoid(outputs).cpu().numpy())  # Use sigmoid to convert logits to probabilities\n",
    "\n",
    "            # Debug information: print batch index and batch size\n",
    "            if batch_idx % 100 == 0:  # Print every 100 batches\n",
    "                print(f\"Processed batch {batch_idx}/{num_batches}, batch size: {len(X_batch)}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_outputs = np.array(all_outputs)\n",
    "    \n",
    "    # Accuracy\n",
    "    predictions = [1 if x > 0.5 else 0 for x in all_outputs]\n",
    "    accuracy = accuracy_score(all_labels, predictions)\n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(all_labels, predictions, zero_division=1)\n",
    "    recall = recall_score(all_labels, predictions)\n",
    "    f1 = f1_score(all_labels, predictions)\n",
    "    \n",
    "    # AUC\n",
    "    auc = roc_auc_score(all_labels, all_outputs)\n",
    "    \n",
    "    # EER Calculation\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_outputs)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, predictions)\n",
    "    \n",
    "    return total_loss / num_batches, accuracy, precision, recall, f1, auc, eer, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57592f1-cb10-4660-99db-d5a0a960f8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs_no_improve = 0\n",
    "n_epochs_stop = 10\n",
    "best_val_loss = float('inf')\n",
    "best_val_eer = float('inf')\n",
    "for epoch in range(config['num_epochs']):\n",
    "    print(f'Starting epoch {epoch+1}/{config[\"num_epochs\"]}')\n",
    "    train_loss = train_model(model, train_val_loader, criterion, optimizer)\n",
    "    \n",
    "    # Validate using the validation set\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1, val_auc, val_eer, cm = evaluate_model(model, create_dataloader(X_val, y_val, config['batch_size']), criterion)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{config[\"num_epochs\"]}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val AUC: {val_auc:.4f}, Val EER: {val_eer:.4f}')\n",
    "       \n",
    "    if val_eer < best_val_eer:\n",
    "        best_val_eer = val_eer\n",
    "        epochs_no_improve = 0\n",
    "        \n",
    "        # Remove the previously saved model if it exists\n",
    "        if os.path.exists(config['model_save_path']):\n",
    "            os.remove(config['model_save_path'])\n",
    "        \n",
    "        # Save the current model\n",
    "        torch.save(model.state_dict(), config['model_save_path'])\n",
    "        print(f'Saved best model with Val EER: {val_eer:.4f} to {config[\"model_save_path\"]}')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_no_improve >= n_epochs_stop:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break\n",
    "\n",
    "        \n",
    "    # Save the best model\n",
    "    # if val_loss < best_val_loss:\n",
    "    #     best_val_loss = val_loss\n",
    "    #     model_save_path = config['model_save_path_template'].format(val_loss)\n",
    "    #     torch.save(model.state_dict(), model_save_path)\n",
    "    #     print(f'Saved best model with Val Loss: {val_loss:.4f} to {model_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de064ff-457b-49ff-b4a4-15d4ced7784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568afb0-5127-4fd1-ac9f-562dbbbcfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, load the best model for testing\n",
    "if os.path.exists(config['model_save_path']):\n",
    "    model.load_state_dict(torch.load(config['model_save_path']))\n",
    "    print(f'Loaded best model from {config[\"model_save_path\"]} for testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702dd23f-a44f-45e0-8691-5431bc63dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model for testing\n",
    "best_model_path = config['model_save_path'].format(best_val_loss)\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064b946-8c25-4361-99cf-5996489bb661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35a63d-8e40-4553-aad5-78fa3144b8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1, test_auc, test_eer, test_cm = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Precision: {test_precision:.4f}')\n",
    "print(f'Test Recall: {test_recall:.4f}')\n",
    "print(f'Test F1: {test_f1:.4f}')\n",
    "print(f'Test AUC: {test_auc:.4f}')\n",
    "print(f'Test EER: {test_eer:.4f}')\n",
    "print(f'Test Confusion Matrix:\\n{test_cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90e577-ac0d-4973-be38-65538ec124e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73283165-cf99-4a14-8f6f-2d8ede43c52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129835e-b756-438a-9474-8ea2b8e33ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf26b07-6d34-4b3c-89ba-21e275ae373f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443145f-dc31-47e9-8ba8-f0c8b990b59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29ae23-168c-458d-bd6c-8ae7ec555111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8585f-10ee-48cf-991d-e77915924c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3efa4-d22d-448e-b515-5285c111abd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e828c7f-e975-4c3e-abce-97663cfe05ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1707d1-d184-43d7-b8aa-4eae3a44eb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e5ee1-9835-4c25-a97b-4917f2b7afd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f300481-ab92-4329-a086-03d04bbbd00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4407a-06fa-44d7-a1d3-4f43b367f113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c93fe-bd20-4873-82bc-926e6c527550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b53c8-45d1-42ea-bfdb-438c06bf5f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb12d5-a4ac-4385-a713-def5e3dc4969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd4bc3-3839-487f-ad05-aa95ecd29bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f196d7e-99a6-48df-937e-4bec6c8a1c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ede26-982e-4513-b843-95b4c6cba004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30ae0a-15df-4721-87cb-539b64647577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Transform y_train to be 1 for the positive class and -1 for the negative class\n",
    "y_train_one_class = np.where(y_train == 1, 1, -1)\n",
    "y_val_one_class = np.where(y_val == 1, 1, -1)\n",
    "y_test_one_class = np.where(y_test == 1, 1, -1)\n",
    "\n",
    "one_class_model = OneClassSVM(kernel=\"rbf\", gamma='scale', nu=0.5)\n",
    "one_class_model.fit(X_train[y_train == 1])  # Train only on the positive class\n",
    "\n",
    "# Evaluate the model\n",
    "val_scores = one_class_model.decision_function(X_val)\n",
    "test_scores = one_class_model.decision_function(X_test)\n",
    "\n",
    "val_auc = roc_auc_score(y_val_one_class, val_scores)\n",
    "test_auc = roc_auc_score(y_test_one_class, test_scores)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val_one_class, np.sign(val_scores))\n",
    "test_accuracy = accuracy_score(y_test_one_class, np.sign(test_scores))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_one_class, test_scores)\n",
    "test_eer = compute_eer(fpr, tpr)\n",
    "\n",
    "print(f\"One-Class SVM - AUC: {test_auc}, Accuracy: {test_accuracy}, EER: {test_eer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0f423-710f-43d5-ac73-6d8dcc616082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to process data in batches\n",
    "def process_in_batches(model, data, batch_size=32):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = data[i:i + batch_size].to(device)\n",
    "            output = model(batch)\n",
    "            results.append(output.cpu().numpy())\n",
    "    return np.concatenate(results)\n",
    "\n",
    "# Transform y_train to be 1 for the positive class and -1 for the negative class\n",
    "y_train_np = y_train.cpu().numpy()\n",
    "y_val_np = y_val.cpu().numpy()\n",
    "y_test_np = y_test.cpu().numpy()\n",
    "\n",
    "y_train_one_class = np.where(y_train_np == 1, 1, -1)\n",
    "y_val_one_class = np.where(y_val_np == 1, 1, -1)\n",
    "y_test_one_class = np.where(y_test_np == 1, 1, -1)\n",
    "\n",
    "# Define One-Class SVM model\n",
    "class OneClassSVM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(OneClassSVM, self).__init__()\n",
    "        self.w = nn.Parameter(torch.randn(input_dim, 1))\n",
    "        self.b = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.w + self.b\n",
    "\n",
    "# Train One-Class SVM only on the positive class\n",
    "positive_X_train = X_train[y_train == 1].clone().detach().float().to(device)\n",
    "model = OneClassSVM(input_dim=positive_X_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i in range(0, len(positive_X_train), batch_size):\n",
    "        batch = positive_X_train[i:i + batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        target = torch.zeros(outputs.shape).to(device)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model using batch processing\n",
    "val_scores = process_in_batches(model, X_val, batch_size)\n",
    "test_scores = process_in_batches(model, X_test, batch_size)\n",
    "\n",
    "val_auc = roc_auc_score(y_val_one_class, val_scores)\n",
    "test_auc = roc_auc_score(y_test_one_class, test_scores)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val_one_class, np.sign(val_scores))\n",
    "test_accuracy = accuracy_score(y_test_one_class, np.sign(test_scores))\n",
    "\n",
    "def compute_eer(fpr, tpr):\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_one_class, test_scores)\n",
    "test_eer = compute_eer(fpr, tpr)\n",
    "\n",
    "print(f\"One-Class SVM - AUC: {test_auc}, Accuracy: {test_accuracy}, EER: {test_eer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e49f025-8331-4dfc-95eb-07a5c5989380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86096fd8-b26b-4366-9945-90a6f61f7e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b7f6d-de53-442f-b196-c46c229a52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9afdb1-5e8b-462e-94f8-e63892841706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508d1d9-34d7-404a-bdab-43f8a6c78115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d5a5db-69f9-4a2d-a588-50541a65b5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47cb3b-31b2-44a4-8cae-dcb1665096f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
